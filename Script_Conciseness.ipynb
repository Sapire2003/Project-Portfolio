{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sapire2003/Project-Portfolio/blob/Data-Analysis/Script_Conciseness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJPh-o0Ch8B"
      },
      "source": [
        "# CSC-206: Text Analytics\n",
        "# Noah Sapire\n",
        "\n",
        "\n",
        "## Assignment 4: Who said what?\n",
        "\n",
        "In this assignment you'll be practicing with the concepts covered in class.\n",
        "\n",
        "There are NO prizes for short, concise code where readability is impacted. However you're free to use concepts and code I use in class.\n",
        "\n",
        "ALWAYS print nicely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvEzk1mBCiqN"
      },
      "source": [
        "### Part 1: What the who?\n",
        "\n",
        "Let's start with some script analysis. Here's a link to the transcribed script of an episodes of the British show Dr. Who. This episode starts in Sheffield, home of the worlds best cutlery (the script says so), AND where I did my Ph.D. These two facts are unrelated.\n",
        "\n",
        "http://www.chakoteya.net/DoctorWho/37-1.html\n",
        "\n",
        "\n",
        "Here's what I want you to do.\n",
        "* Read this script from the website\n",
        "  * the encoding is utf-8\n",
        "* Extract the names of the people speaking\n",
        "* Generate a graph showing who is talking to who, just like with the Game of Thrones script\n",
        "* Only include instances where people talk to someone else a minimum of **2 times**.\n",
        "* Looking at the resulting graph, tell me who you think appears in only one scene\n",
        "\n",
        "This is a little harder than the Game of Thrones script. Why? Because in the GoT script characters were explicitly indicated in the HTML markup (that div class = 'Character' bit). That's not true this time, and I'd suggest that what you're about to deal with is more normal in unstructured text. This makes using something like BeautifulSoup much much harder. You're welcome to use it, but you can do this entirely manually, using the find/while loop approach we first used on the GoT script, and indeed I'd recommend you start there regardless.\n",
        "\n",
        "That said, the text does have some structure. Let me give you some hints of what to do:\n",
        "\n",
        "* Make sure you take a look at the raw html. You'll need to, in order to indentify patterns in the text\n",
        "* It will help to find something before the main script starts, and after it ends (remember how I used a while loop in GoT)\n",
        "* Notice that there are repeating patterns. The name of the character is always followed by a ' : '\n",
        "* There are lots of ways you can do this, but I'd start with thinking about using the following two methods:\n",
        "  * str.find(pattern, start_index, stop_index)\n",
        "  * str.rfind(pattern, start_index, stop_index)\n",
        "  * find we've used before, and it finds the FIRST index where the pattern occurs (in the given range)\n",
        "  * rfind finds the LAST index in the given range\n",
        "  * e.g. try:\n",
        "    * 'mississippi'.find('i',0,6)\n",
        "    * 'mississippi'.rfind('i',0,6)\n",
        "* You'll have to do some tinkering to get this code to work. This is VERY normal\n",
        "* Once you do, extract the names and append them in order to a list\n",
        "* THEN make a list of BIGRAMS - the word pairs of what name follows another name\n",
        "  * You can use the code I did in class to do that\n",
        "  * OR you can wait until later next week, when I'll show you how to generate bigrams using the NLTK\n",
        "* Only when you've finished, try feeding your code this web page from the same archive.\n",
        "\n",
        "> http://www.chakoteya.net/DoctorWho/28-7.htm\n",
        "\n",
        "* **I don't want to see the resulting graph**. I want to know IF it worked, without you having to edit your code. It's ok if it doesn't work.\n",
        "* If it didn't work, TELL ME why not?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbK9i2tA-Wlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0eec2ca-44a7-4fd7-df1d-4f339c8eae43"
      },
      "source": [
        "# Do part 1 here. Create extra cells as you need them.\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fileName = \"http://www.chakoteya.net/DoctorWho/37-1.html\"\n",
        "response = urllib.request.urlopen(fileName)\n",
        "data = response.read()\n",
        "text = data.decode('utf-8')"
      ],
      "metadata": {
        "id": "zzH6ebTu10wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_script = text.find('<title>')\n",
        "end_script = text.find('</font></td>')\n",
        "realText = text[start_script+7:end_script]"
      ],
      "metadata": {
        "id": "nWgHT4MJ5O_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = start_script\n",
        "\n",
        "while start < end_script:\n",
        "\n",
        "\n",
        "  startStep = text.find('<title',start)\n",
        "  endStep = text.find('>',startStep)\n",
        "\n",
        "  #stepTmp = text[startStep:endStep]\n",
        "  #print(stepTmp)\n",
        "\n",
        "  actualTextEnd = text.find('\\r',endStep)\n",
        "  stepTmp = text[endStep+1:actualTextEnd]\n",
        "  #print(stepTmp)\n",
        "\n",
        "  start = text.find('\\r',endStep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "nFp3s70vaKB4",
        "outputId": "91356293-8188-4870-8065-4636a0553621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-77a62f572771>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mstartStep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mendStep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#stepTmp = text[startStep:endStep]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outText = ''\n",
        "\n",
        "start = start_script\n",
        "\n",
        "while start < end_script:\n",
        "\n",
        "\n",
        "  startStep = text.find('<div class=',start)\n",
        "  endStep = text.find('>',startStep)\n",
        "\n",
        "  stepTmp = text[startStep:endStep]\n",
        "  if stepTmp.find('Character') != -1:\n",
        "\n",
        "    actualTextEnd = text.find('</div>',endStep)\n",
        "    stepTmp = text[endStep+1:actualTextEnd]\n",
        "    outText = outText + stepTmp + ' '\n",
        "\n",
        "  start = text.find('<div class',endStep)\n",
        "\n",
        "print(outText)"
      ],
      "metadata": {
        "id": "yfq5uGawb7hP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "8c004bea-6931-4c3c-bbf7-859b4b24768c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1f3b34bfccf7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mstartStep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<div class='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mendStep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mstepTmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartStep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mendStep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph()\n",
        "\n",
        "edge_thick = []\n",
        "vsum = 0\n",
        "unique = []\n",
        "\n",
        "for key,value in REPLACE_THIS_WITH_COUNTER_OF_THE_TUPLES.items():\n",
        "  if value > 1:\n",
        "    name1,name2 = key\n",
        "    unique.append(name1)\n",
        "    g.add_edge(name1, name2, weight=1)\n",
        "    edge_thick.append(value)\n",
        "    vsum+= value\n",
        "\n",
        "edge_thick2 = [(value/vsum)*50 for value in edge_thick]\n",
        "\n",
        "pos = nx.spring_layout(g,k=2)\n",
        "\n",
        "node_colors = range(len(g))\n",
        "M = g.number_of_edges()\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "nodes = nx.draw_networkx_nodes(g,pos,node_size = 3000, node_color=node_colors, cmap=plt.cm.Reds)\n",
        "edges = nx.draw_networkx_edges(g,pos,arrowstyle='->',arrowsize=50,edge_color='black', width=edge_thick2)\n",
        "\n",
        "nx.draw_networkx_labels(g, pos)\n",
        "ax = plt.gca()\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EAqHcmmHWjGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "id": "pXd5lveUQPjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-YtFufsG9bk"
      },
      "source": [
        "### Part 2: The past and the president\n",
        "\n",
        "In assignment 2, I asked you to analyze FOUR speeches by presidents. NOW I want you to do it again, but with more specifics.\n",
        "\n",
        "For each presidential speech, I want you to:\n",
        "\n",
        "* Read in the text\n",
        "* Print how many SENTENCES are in each speech\n",
        "* Print the average number of words there are per sentence\n",
        "  * Use the sent_tokenize method\n",
        "  * Include ALL words in this count (i.e. don't do any cleaning)\n",
        "* Use the word_tokenize methods to split the entire text into words\n",
        "* Remove punctuation, stop words, AND words that are SHORTER than 3 characters\n",
        "* Print how many words there are in the speech AFTER this cleaning\n",
        "* Print the average length of these cleaned words\n",
        "* Print the lexical density of the cleaned words\n",
        "* Print the 10 most common words, with counts\n",
        "* Print the 5 most common BIGRAMS with counts\n",
        "* Show a wordcloud of the single words\n",
        "* Show a wordcloud of the bigrams\n",
        "* Give me a write up comparing this analysis to yours from Assignment 2. Did anything change significantly?\n",
        "* Also compare the wordclouds in this assignment to each other. Which of the single words or the bigrams do you find more revealing, and why?\n",
        "\n",
        "There's a lot of processing here, and you could write a LOT of code. Try to think about how you divide this up so you don't just copy and paste a lot of code again and again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSEaEXq0Lpxs"
      },
      "source": [
        "# I've started you off here, by importing the NLTK\n",
        "# including the two methods I want you to use\n",
        "# and the stopwords\n",
        "# You will get an error the first time you try to use\n",
        "# these (like in the cell below), but you should be able to fix it\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NJW debug\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxk11uC27AAC",
        "outputId": "dc0c0385-97da-4491-fc8f-aff1dc2f1de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrWcog47OAw4",
        "collapsed": true
      },
      "source": [
        "stop = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "presidents = {'Barack Obama':'BarackObama_2009.txt','George Washington':'GeorgeWashington_1790.txt','Ronald Reagon':'RonaldReagan_1982.txt','Donald Trump':'DonaldTrump_2017.txt'}\n",
        "total_words = {}\n",
        "clean_words = {}\n",
        "unique_words = {}\n",
        "lexical_density = {}\n",
        "average_length = {}\n",
        "america_uses = {}\n",
        "lineAvg = {}\n",
        "sentences = {}\n",
        "#NJW path = '/content/drive/My Drive/'\n",
        "path = '/content/drive/My Drive/Colab Notebooks/CSC206/Data/'\n",
        "\n"
      ],
      "metadata": {
        "id": "8Dlt-FycgU0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipelineText(text):\n",
        "  sents = sent_tokenize(text)\n",
        "  lower_sents = [sentence.lower() for sentence in sents]\n",
        "  stopped_sents = [word for sentence in lower_sents for word in sentence.split() if word in stop == False]\n",
        "  return(stopped_sents)\n",
        "\n",
        "for files in presidents:\n",
        "  myFile = path+presidents[files]\n",
        "  data = open(myFile,'r')\n",
        "  text = data.read()\n",
        "\n",
        "  #lines\n",
        "  lines = sent_tokenize(text)\n",
        "  sentences[files] = len(lines)\n",
        "  print(lines)\n",
        "  line_lengths = 0\n",
        "  for line in lines:\n",
        "    line_lengths += len(line)\n",
        "  lineAvg[files] = line_lengths / len(lines)\n",
        "\n",
        "  #cleaning\n",
        "  all_words = word_tokenize(text)\n",
        "  final_words = pipelineText(all_words)\n",
        "  clean_tokens = [token.lower() for token in final_words if token not in string.punctuation and token.lower() not in stop and not len(token) <= 3]\n",
        "\n",
        "  #avg word length\n",
        "  wordLens = [len(word) for word in clean_tokens]\n",
        "  small = min(wordLens)\n",
        "  big = max(wordLens)\n",
        "  avg = sum(wordLens)/len(wordLens)\n",
        "  njw_vocab = set(clean_tokens)\n",
        "  unique_len = len(njw_vocab)\n",
        "\n",
        "  unique_words[files] = unique_len\n",
        "  lexical_density[files] = unique_len/len(wordLens)\n",
        "  average_length[files] = avg\n",
        "  america_uses[files] = clean_tokens.count('america')\n",
        "\n",
        "  counter_tokens = Counter(clean_tokens)\n",
        "  top_common_tokens = counter_tokens.most_common(10)\n",
        "\n",
        "  bigram_list = []\n",
        "  n1 = clean_tokens[0]\n",
        "\n",
        "  for n2 in clean_tokens[1:]:\n",
        "    bi = n1 + ' ' + n2\n",
        "    bigram_list.append(bi)\n",
        "    n1 = n2\n",
        "\n",
        "  counter_bigram = Counter(bigram_list)\n",
        "  top_common_tokens = counter_bigram.most_common(5)\n",
        "\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.figure(figsize=(8,8))\n",
        "\n",
        "  wordcloud = WordCloud(width=800,height=800, min_font_size=14).generate(unique_words)\n",
        "  plt.imshow(wc)\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Single Words\")\n",
        "  plt.show()\n",
        "\n",
        "#NJW Debugging, remove errant comma\n",
        "  wc = wordcloud.generate_from_frequencies(bigram_list)\n",
        "  plt.imshow(wc)\n",
        "  plt.show()\n",
        "\n",
        "  wordcloud = WordCloud(width=800,height=800, min_font_size=14).generate(bigram_list)\n",
        "\n",
        "  plt.imshow(wordcloud)\n",
        "\n",
        "  plt.title(\"Bigrams\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "RJMV27OFgVkp",
        "outputId": "5305d83d-9411-4fc6-b65a-b3f195b34af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Madame Speaker, Mr. Vice President, Members of Congress, and the First Lady of the United States:\\n\\nI've come here tonight not only to address the distinguished men and women in this great chamber, but to speak frankly and directly to the men and women who sent us here.\", 'I know that for many Americans watching right now, the state of our economy is a concern that rises above all others.', 'And rightly so.', \"If you haven't been personally affected by this recession, you probably know someone who has - a friend; a neighbor; a member of your family.\", \"You don't need to hear another list of statistics to know that our economy is in crisis, because you live it every day.\", \"It's the worry you wake up with and the source of sleepless nights.\", \"It's the job you thought you'd retire from but now have lost; the business you built your dreams upon that's now hanging by a thread; the college acceptance letter your child had to put back in the envelope.\", 'The impact of this recession is real, and it is everywhere.', 'But while our economy may be weakened and our confidence shaken; though we are living through difficult and uncertain times, tonight I want every American to know this:\\n\\nWe will rebuild, we will recover, and the United States of America will emerge stronger than before.', 'The weight of this crisis will not determine the destiny of this nation.', \"The answers to our problems don't lie beyond our reach.\", 'They exist in our laboratories and universities; in our fields and our factories; in the imaginations of our entrepreneurs and the pride of the hardest-working people on Earth.', 'Those qualities that have made America the greatest force of progress and prosperity in human history we still possess in ample measure.', 'What is required now is for this country to pull together, confront boldly the challenges we face, and take responsibility for our future once more.', \"Now, if we're honest with ourselves, we'll admit that for too long, we have not always met these responsibilities — as a government or as a people.\", \"I say this not to lay blame or look backwards, but because it is only by understanding how we arrived at this moment that we'll be able to lift ourselves out of this predicament.\", 'The fact is, our economy did not fall into decline overnight.', 'Nor did all of our problems begin when the housing market collapsed or the stock market sank.', 'We have known for decades that our survival depends on finding new sources of energy.', 'Yet we import more oil today than ever before.', 'The cost of health care eats up more and more of our savings each year, yet we keep delaying reform.', 'Our children will compete for jobs in a global economy that too many of our schools do not prepare them for.', 'And though all these challenges went unsolved, we still managed to spend more money and pile up more debt, both as individuals and through our government, than ever before.', 'In other words, we have lived through an era where too often, short-term gains were prized over long-term prosperity; where we failed to look beyond the next payment, the next quarter, or the next election.', 'A surplus became an excuse to transfer wealth to the wealthy instead of an opportunity to invest in our future.', 'Regulations were gutted for the sake of a quick profit at the expense of a healthy market.', \"People bought homes they knew they couldn't afford from banks and lenders who pushed those bad loans anyway.\", 'And all the while, critical debates and difficult decisions were put off for some other time on some other day.', 'Well that day of reckoning has arrived, and the time to take charge of our future is here.', 'Now is the time to act boldly and wisely — to not only revive this economy, but to build a new foundation for lasting prosperity.', 'Now is the time to jumpstart job creation, re-start lending, and invest in areas like energy, health care, and education that will grow our economy, even as we make hard choices to bring our deficit down.', \"That is what my economic agenda is designed to do, and that's what I'd like to talk to you about tonight.\", \"It's an agenda that begins with jobs.\", \"As soon as I took office, I asked this Congress to send me a recovery plan by President's Day that would put people back to work and put money in their pockets.\", \"Not because I believe in bigger government — I don't.\", \"Not because I'm not mindful of the massive debt we've inherited — I am.\", 'I called for action because the failure to do so would have cost more jobs and caused more hardships.', 'In fact, a failure to act would have worsened our long-term deficit by assuring weak economic growth for years.', \"That's why I pushed for quick action.\", 'And tonight, I am grateful that this Congress delivered, and pleased to say that the American Recovery and Reinvestment Act is now law.', 'Over the next two years, this plan will save or create 3.5 million jobs.More than 90% of these jobs will be in the private sector — jobs rebuilding our roads and bridges; constructing wind turbines and solar panels; laying broadband and expanding mass transit.', 'Because of this plan, there are teachers who can now keep their jobs and educate our kids.', 'Health care professionals can continue caring for our sick.', 'There are 57 police officers who are still on the streets of Minneapolis tonight because this plan prevented the layoffs their department was about to make.', 'Because of this plan, 95% of the working households in America will receive a tax cut — a tax cut that you will see in your paychecks beginning on April 1st.', 'Because of this plan, families who are struggling to pay tuition costs will receive a $2,500 tax credit for all four years of college.', 'And Americans who have lost their jobs in this recession will be able to receive extended unemployment benefits and continued health care coverage to help them weather this storm.', 'I know there are some in this chamber and watching at home who are skeptical of whether this plan will work.', 'I understand that skepticism.', \"Here in Washington, we've all seen how quickly good intentions can turn into broken promises and wasteful spending.\", 'And with a plan of this scale comes enormous responsibility to get it right.', 'That is why I have asked Vice President Biden to lead a tough, unprecedented oversight effort — because nobody messes with Joe.', 'I have told each member of my Cabinet as well as mayors and governors across the country that they will be held accountable by me and the American people for every dollar they spend.', 'I have appointed a proven and aggressive Inspector General to ferret out any and all cases of waste and fraud.', 'And we have created a new website called recovery.gov so that every American can find out how and where their money is being spent.', 'So the recovery plan we passed is the first step in getting our economy back on track.', 'But it is just the first step.', 'Because even if we manage this plan flawlessly, there will be no real recovery unless we clean up the credit crisis that has severely weakened our financial system.', \"I want to speak plainly and candidly about this issue tonight, because every American should know that it directly affects you and your family's well-being.\", \"You should also know that the money you've deposited in banks across the country is safe; your insurance is secure; and you can rely on the continued operation of our financial system.\", 'That is not the source of concern.', 'The concern is that if we do not re-start lending in this country, our recovery will be choked off before it even begins.', 'You see, the flow of credit is the lifeblood of our economy.', 'The ability to get a loan is how you finance the purchase of everything from a home to a car to a college education; how stores stock their shelves, farms buy equipment, and businesses make payroll.', 'But credit has stopped flowing the way it should.', 'Too many bad loans from the housing crisis have made their way onto the books of too many banks.', 'With so much debt and so little confidence, these banks are now fearful of lending out any more money to households, to businesses, or to each other.', \"When there is no lending, families can't afford to buy homes or cars.\", 'So businesses are forced to make layoffs.', 'Our economy suffers even more, and credit dries up even further.', 'That is why this administration is moving swiftly and aggressively to break this destructive cycle, restore confidence, and re-start lending.', 'We will do so in several ways.', 'First, we are creating a new lending fund that represents the largest effort ever to help provide auto loans, college loans, and small business loans to the consumers and entrepreneurs who keep this economy running.', 'Second, we have launched a housing plan that will help responsible families facing the threat of foreclosure lower their monthly payments and re-finance their mortgages.', \"It's a plan that won't help speculators or that neighbor down the street who bought a house he could never hope to afford, but it will help millions of Americans who are struggling with declining home values - Americans who will now be able to take advantage of the lower interest rates that this plan has already helped bring about.\", 'In fact, the average family who re-finances today can save nearly $2000 per year on their mortgage.', 'Third, we will act with the full force of the federal government to ensure that the major banks that Americans depend on have enough confidence and enough money to lend even in more difficult times.', 'And when we learn that a major bank has serious problems, we will hold accountable those responsible, force the necessary adjustments, provide the support to clean up their balance sheets, and assure the continuity of a strong, viable institution that can serve our people and our economy.', 'I understand that on any given day, Wall Street may be more comforted by an approach that gives banks bailouts with no strings attached, and that holds nobody accountable for their reckless decisions.', \"But such an approach won't solve the problem.\", 'And our goal is to quicken the day when we re-start lending to the American people and American business and end this crisis once and for all.', 'I intend to hold these banks fully accountable for the assistance they receive, and this time, they will have to clearly demonstrate how taxpayer dollars result in more lending for the American taxpayer.', \"This time, CEOs won't be able to use taxpayer money to pad their paychecks or buy fancy drapes or disappear on a private jet.\", 'Those days are over.', \"Still, this plan will require significant resources from the federal government — and yes, probably more than we've already set aside.\", 'But while the cost of action will be great, I can assure you that the cost of inaction will be far greater, for it could result in an economy that sputters along for not months or years, but perhaps a decade.', 'That would be worse for our deficit, worse for business, worse for you, and worse for the next generation.', 'And I refuse to let that happen.', 'I understand that when the last administration asked this Congress to provide assistance for struggling banks, Democrats and Republicans alike were infuriated by the mismanagement and results that followed.', 'So were the American taxpayers.', 'So was I.', 'So I know how unpopular it is to be seen as helping banks right now, especially when everyone is suffering in part from their bad decisions.', 'I promise you - I get it.', 'But I also know that in a time of crisis, we cannot afford to govern out of anger, or yield to the politics of the moment.', 'My job — our job — is to solve the problem.', 'Our job is to govern with a sense of responsibility.', \"I will not spend a single penny for the purpose of rewarding a single Wall Street executive, but I will do whatever it takes to help the small business that can't pay its workers or the family that has saved and still can't get a mortgage.\", \"That's what this is about.\", \"It's not about helping banks — it's about helping people.\", 'Because when credit is available again, that young family can finally buy a new home.', 'And then some company will hire workers to build it.', \"And then those workers will have money to spend, and if they can get a loan too, maybe they'll finally buy that car, or open their own business.\", 'Investors will return to the market, and American families will see their retirement secured once more.', 'Slowly, but surely, confidence will return, and our economy will recover.', 'So I ask this Congress to join me in doing whatever proves necessary.', 'Because we cannot consign our nation to an open-ended recession.', 'And to ensure that a crisis of this magnitude never happens again, I ask Congress to move quickly on legislation that will finally reform our outdated regulatory system.', 'It is time to put in place tough, new common-sense rules of the road so that our financial market rewards drive and innovation, and punishes short-cuts and abuse.', \"The recovery plan and the financial stability plan are the immediate steps we're taking to revive our economy in the short-term.\", \"But the only way to fully restore America's economic strength is to make the long-term investments that will lead to new jobs, new industries, and a renewed ability to compete with the rest of the world.\", \"The only way this century will be another American century is if we confront at last the price of our dependence on oil and the high cost of health care; the schools that aren't preparing our children and the mountain of debt they stand to inherit.\", 'That is our responsibility.', 'In the next few days, I will submit a budget to Congress.', 'So often, we have come to view these documents as simply numbers on a page or laundry lists of programs.', 'I see this document differently.', 'I see it as a vision for America — as a blueprint for our future.', 'My budget does not attempt to solve every problem or address every issue.', \"It reflects the stark reality of what we've inherited — a trillion dollar deficit, a financial crisis, and a costly recession.\", 'Given these realities, everyone in this chamber - Democrats and Republicans — will have to sacrifice some worthy priorities for which there are no dollars.', 'And that includes me.', 'But that does not mean we can afford to ignore our long-term challenges.', 'I reject the view that says our problems will simply take care of themselves; that says government has no role in laying the foundation for our common prosperity.', 'For history tells a different story.', 'History reminds us that at every moment of economic upheaval and transformation, this nation has responded with bold action and big ideas.', 'In the midst of civil war, we laid railroad tracks from one coast to another that spurred commerce and industry.', 'From the turmoil of the Industrial Revolution came a system of public high schools that prepared our citizens for a new age.', 'In the wake of war and depression, the GI Bill sent a generation to college and created the largest middle-class in history.', 'And a twilight struggle for freedom led to a nation of highways, an American on the moon, and an explosion of technology that still shapes our world.', \"In each case, government didn't supplant private enterprise; it catalyzed private enterprise.\", 'It created the conditions for thousands of entrepreneurs and new businesses to adapt and to thrive.', 'We are a nation that has seen promise amid peril, and claimed opportunity from ordeal.', 'Now we must be that nation again.', \"That is why, even as it cuts back on the programs we don't need, the budget I submit will invest in the three areas that are absolutely critical to our economic future: energy, health care, and education.\", 'It begins with energy.', 'We know the country that harnesses the power of clean, renewable energy will lead the 21st century.', 'And yet, it is China that has launched the largest effort in history to make their economy energy efficient.', \"We invented solar technology, but we've fallen behind countries like Germany and Japan in producing it.\", 'New plug-in hybrids roll off our assembly lines, but they will run on batteries made in Korea.', \"Well I do not accept a future where the jobs and industries of tomorrow take root beyond our borders - and I know you don't either.\", 'It is time for America to lead again.', \"Thanks to our recovery plan, we will double this nation's supply of renewable energy in the next three years.\", 'We have also made the largest investment in basic research funding in American history - an investment that will spur not only new discoveries in energy, but breakthroughs in medicine, science, and technology.', 'We will soon lay down thousands of miles of power lines that can carry new energy to cities and towns across this country.', 'And we will put Americans to work making our homes and buildings more efficient so that we can save billions of dollars on our energy bills.', 'But to truly transform our economy, protect our security, and save our planet from the ravages of climate change, we need to ultimately make clean, renewable energy the profitable kind of energy.', 'So I ask this Congress to send me legislation that places a market-based cap on carbon pollution and drives the production of more renewable energy in America.', 'And to support that innovation, we will invest fifteen billion dollars a year to develop technologies like wind power and solar power; advanced biofuels, clean coal, and more fuel-efficient cars and trucks built right here in America.', 'As for our auto industry, everyone recognizes that years of bad decision-making and a global recession have pushed our automakers to the brink.', 'We should not, and will not, protect them from their own bad practices.', 'But we are committed to the goal of a re-tooled, re-imagined auto industry that can compete and win.', 'Millions of jobs depend on it.', 'Scores of communities depend on it.', 'And I believe the nation that invented the automobile cannot walk away from it.', 'None of this will come without cost, nor will it be easy.', 'But this is America.', \"We don't do what's easy.\", 'We do what is necessary to move this country forward.', 'For that same reason, we must also address the crushing cost of health care.', 'This is a cost that now causes a bankruptcy in America every thirty seconds.', 'By the end of the year, it could cause 1.5 million Americans to lose their homes.', 'In the last eight years, premiums have grown four times faster than wages.', 'And in each of these years, one million more Americans have lost their health insurance.', 'It is one of the major reasons why small businesses close their doors and corporations ship jobs overseas.', \"And it's one of the largest and fastest-growing parts of our budget.\", 'Given these facts, we can no longer afford to put health care reform on hold.', 'Already, we have done more to advance the cause of health care reform in the last thirty days than we have in the last decade.', 'When it was days old, this Congress passed a law to provide and protect health insurance for eleven million American children whose parents work full-time.', 'Our recovery plan will invest in electronic health records and new technology that will reduce errors, bring down costs, ensure privacy, and save lives.', 'It will launch a new effort to conquer a disease that has touched the life of nearly every American by seeking a cure for cancer in our time.', 'And it makes the largest investment ever in preventive care, because that is one of the best ways to keep our people healthy and our costs under control.', 'This budget builds on these reforms.', 'It includes an historic commitment to comprehensive health care reform — a down-payment on the principle that we must have quality, affordable health care for every American.', \"It's a commitment that's paid for in part by efficiencies in our system that are long overdue.\", \"And it's a step we must take if we hope to bring down our deficit in the years to come.\", \"Now, there will be many different opinions and ideas about how to achieve reform, and that is why I'm bringing together businesses and workers, doctors and health care providers, Democrats and Republicans to begin work on this issue next week.\", 'I suffer no illusions that this will be an easy process.', 'It will be hard.', 'But I also know that nearly a century after Teddy Roosevelt first called for reform, the cost of our health care has weighed down our economy and the conscience of our nation long enough.', 'So let there be no doubt: health care reform cannot wait, it must not wait, and it will not wait another year.', 'The third challenge we must address is the urgent need to expand the promise of education in America.', 'In a global economy where the most valuable skill you can sell is your knowledge, a good education is no longer just a pathway to opportunity — it is a pre-requisite.', 'Right now, three-quarters of the fastest-growing occupations require more than a high school diploma.', 'And yet, just over half of our citizens have that level of education.', 'We have one of the highest high school dropout rates of any industrialized nation.', 'And half of the students who begin college never finish.', 'This is a prescription for economic decline, because we know the countries that out-teach us today will out-compete us tomorrow.', 'That is why it will be the goal of this administration to ensure that every child has access to a complete and competitive education — from the day they are born to the day they begin a career.', 'Already, we have made an historic investment in education through the economic recovery plan.', 'We have dramatically expanded early childhood education and will continue to improve its quality, because we know that the most formative learning comes in those first years of life.', 'We have made college affordable for nearly seven million more students.', \"And we have provided the resources necessary to prevent painful cuts and teacher layoffs that would set back our children's progress.\", \"But we know that our schools don't just need more resources.\", 'They need more reform.', 'That is why this budget creates new incentives for teacher performance; pathways for advancement, and rewards for success.', \"We'll invest in innovative programs that are already helping schools meet high standards and close achievement gaps.\", 'And we will expand our commitment to charter schools.', 'It is our responsibility as lawmakers and educators to make this system work.', 'But it is the responsibility of every citizen to participate in it.', 'And so tonight, I ask every American to commit to at least one year or more of higher education or career training.', 'This can be community college or a four-year school; vocational training or an apprenticeship.', 'But whatever the training may be, every American will need to get more than a high school diploma.', 'And dropping out of high school is no longer an option.', \"It's not just quitting on yourself, it's quitting on your country — and this country needs and values the talents of every American.\", 'That is why we will provide the support necessary for you to complete college and meet a new goal: by 2020, America will once again have the highest proportion of college graduates in the world.', 'I know that the price of tuition is higher than ever, which is why if you are willing to volunteer in your neighborhood or give back to your community or serve your country, we will make sure that you can afford a higher education.', 'And to encourage a renewed spirit of national service for this and future generations, I ask this Congress to send me the bipartisan legislation that bears the name of Senator Orrin Hatch as well as an American who has never stopped asking what he can do for his country — Senator Edward Kennedy.', 'These education policies will open the doors of opportunity for our children.', 'But it is up to us to ensure they walk through them.', 'In the end, there is no program or policy that can substitute for a mother or father who will attend those parent/teacher conferences, or help with homework after dinner, or turn off the TV, put away the video games, and read to their child.', \"I speak to you not just as a President, but as a father when I say that responsibility for our children's education must begin at home.\", 'There is, of course, another responsibility we have to our children.', 'And that is the responsibility to ensure that we do not pass on to them a debt they cannot pay.', 'With the deficit we inherited, the cost of the crisis we face, and the long-term challenges we must meet, it has never been more important to ensure that as our economy recovers, we do what it takes to bring this deficit down.', \"I'm proud that we passed the recovery plan free of earmarks, and I want to pass a budget next year that ensures that each dollar we spend reflects only our most important national priorities.\", 'Yesterday, I held a fiscal summit where I pledged to cut the deficit in half by the end of my first term in office.', 'My administration has also begun to go line by line through the federal budget in order to eliminate wasteful and ineffective programs.', 'As you can imagine, this is a process that will take some time.', \"But we're starting with the biggest lines.\", 'We have already identified two trillion dollars in savings over the next decade.', \"In this budget, we will end education programs that don't work and end direct payments to large agribusinesses that don't need them.\", \"We'll eliminate the no-bid contracts that have wasted billions in Iraq, and reform our defense budget so that we're not paying for Cold War-era weapons systems we don't use.\", \"We will root out the waste, fraud, and abuse in our Medicare program that doesn't make our seniors any healthier, and we will restore a sense of fairness and balance to our tax code by finally ending the tax breaks for corporations that ship our jobs overseas.\", 'In order to save our children from a future of debt, we will also end the tax breaks for the wealthiest 2% of Americans.', \"But let me perfectly clear, because I know you'll hear the same old claims that rolling back these tax breaks means a massive tax increase on the American people: if your family earns less than $250,000 a year, you will not see your taxes increased a single dime.\", 'I repeat: not one single dime.', \"In fact, the recovery plan provides a tax cut — that's right, a tax cut — for 95% of working families.\", 'And these checks are on the way.', 'To preserve our long-term fiscal health, we must also address the growing costs in Medicare and Social Security.', 'Comprehensive health care reform is the best way to strengthen Medicare for years to come.', 'And we must also begin a conversation on how to do the same for Social Security, while creating tax-free universal savings accounts for all Americans.', \"Finally, because we're also suffering from a deficit of trust, I am committed to restoring a sense of honesty and accountability to our budget.\", 'That is why this budget looks ahead ten years and accounts for spending that was left out under the old rules - and for the first time, that includes the full cost of fighting in Iraq and Afghanistan.', 'For seven years, we have been a nation at war.', 'No longer will we hide its price.', 'We are now carefully reviewing our policies in both wars, and I will soon announce a way forward in Iraq that leaves Iraq to its people and responsibly ends this war.', 'And with our friends and allies, we will forge a new and comprehensive strategy for Afghanistan and Pakistan to defeat al Qaeda and combat extremism.', 'Because I will not allow terrorists to plot against the American people from safe havens half a world away.', 'As we meet here tonight, our men and women in uniform stand watch abroad and more are readying to deploy.', 'To each and every one of them, and to the families who bear the quiet burden of their absence, Americans are united in sending one message: we honor your service, we are inspired by your sacrifice, and you have our unyielding support.', 'To relieve the strain on our forces, my budget increases the number of our soldiers and Marines.', 'And to keep our sacred trust with those who serve, we will raise their pay, and give our veterans the expanded health care and benefits that they have earned.', 'To overcome extremism, we must also be vigilant in upholding the values our troops defend — because there is no force in the world more powerful than the example of America.', \"That is why I have ordered the closing of the detention center at Guantanamo Bay, and will seek swift and certain justice for captured terrorists - because living our values doesn't make us weaker, it makes us safer and it makes us stronger.\", 'And that is why I can stand here tonight and say without exception or equivocation that the United States of America does not torture.', 'In words and deeds, we are showing the world that a new era of engagement has begun.', 'For we know that America cannot meet the threats of this century alone, but the world cannot meet them without America.', 'We cannot shun the negotiating table, nor ignore the foes or forces that could do us harm.', 'We are instead called to move forward with the sense of confidence and candor that serious times demand.', 'To seek progress toward a secure and lasting peace between Israel and her neighbors, we have appointed an envoy to sustain our effort.', 'To meet the challenges of the 21st century - from terrorism to nuclear proliferation; from pandemic disease to cyber threats to crushing poverty — we will strengthen old alliances, forge new ones, and use all elements of our national power.', 'And to respond to an economic crisis that is global in scope, we are working with the nations of the G-20 to restore confidence in our financial system, avoid the possibility of escalating protectionism, and spur demand for American goods in markets across the globe.', \"For the world depends on us to have a strong economy, just as our economy depends on the strength of the world's.\", 'As we stand at this crossroads of history, the eyes of all people in all nations are once again upon us - watching to see what we do with this moment; waiting for us to lead.', 'Those of us gathered here tonight have been called to govern in extraordinary times.', 'It is a tremendous burden, but also a great privilege - one that has been entrusted to few generations of Americans.', 'For in our hands lies the ability to shape our world for good or for ill.', 'I know that it is easy to lose sight of this truth — to become cynical and doubtful; consumed with the petty and the trivial.', 'But in my life, I have also learned that hope is found in unlikely places; that inspiration often comes not from those with the most power or celebrity, but from the dreams and aspirations of Americans who are anything but ordinary.', 'I think about Leonard Abess, the bank president from Miami who reportedly cashed out of his company, took a $60 million bonus, and gave it out to all 399 people who worked for him, plus another 72 who used to work for him.', \"He didn't tell anyone, but when the local newspaper found out, he simply said, I knew some of these people since I was 7 years old.\", 'I didn\\'t feel right getting the money myself.\"', 'I think about Greensburg, Kansas, a town that was completely destroyed by a tornado, but is being rebuilt by its residents as a global example of how clean energy can power an entire community - how it can bring jobs and businesses to a place where piles of bricks and rubble once lay.', '\"The tragedy was terrible,\" said one of the men who helped them rebuild.', '\"But the folks here know that it also provided an incredible opportunity.\"', \"And I think about Ty'Sheoma Bethea, the young girl from that school I visited in Dillon, South Carolina — a place where the ceilings leak, the paint peels off the walls, and they have to stop teaching six times a day because the train barrels by their classroom.\", 'She has been told that her school is hopeless, but the other day after class she went to the public library and typed up a letter to the people sitting in this room.', 'She even asked her principal for the money to buy a stamp.', 'The letter asks us for help, and says, \"We are just students trying to become lawyers, doctors, congressmen like yourself and one day president, so we can make a change to not just the state of South Carolina but also the world.', 'We are not quitters.\"', 'We are not quitters.', 'These words and these stories tell us something about the spirit of the people who sent us here.', 'They tell us that even in the most trying times, amid the most difficult circumstances, there is a generosity, a resilience, a decency, and a determination that perseveres; a willingness to take responsibility for our future and for posterity.', 'Their resolve must be our inspiration.', 'Their concerns must be our cause.', 'And we must show them and all our people that we are equal to the task before us.', \"I know that we haven't agreed on every issue thus far, and there are surely times in the future when we will part ways.\", 'But I also know that every American who is sitting here tonight loves this country and wants it to succeed.', 'That must be the starting point for every debate we have in the coming months, and where we return after those debates are done.', 'That is the foundation on which the American people expect us to build common ground.', 'And if we do — if we come together and lift this nation from the depths of this crisis; if we put our people back to work and restart the engine of our prosperity; if we confront without fear the challenges of our time and summon that enduring spirit of an America that does not quit, then someday years from now our children can tell their children that this was the time when we performed, in the words that are carved into this very chamber, \"something worthy to be remembered.\"', 'Thank you, God Bless you, and may God Bless the United States of America.']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a67b884ff4be>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m#cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mfinal_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipelineText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mclean_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a67b884ff4be>\u001b[0m in \u001b[0;36mpipelineText\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpipelineText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mlower_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstopped_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlower_sents\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopped_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \"\"\"\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[1;32m   1458\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mprevious_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mprevious_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;31m# Get the slice of the previous word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for president, value in unique_words.items():\n",
        "  print(\"President: \" + president + \". Unique words in address: \" + str(value))\n",
        "\n",
        "for president, value in lexical_density.items():\n",
        "  print(\"President: \" + president + \". Lexical density in address: \" + str(round(value,2)))\n",
        "\n",
        "for president, value in average_length.items():\n",
        "  print(\"President: \" + president + \". Average word length in address: \" + str(round(value,2)))\n",
        "\n",
        "for president, value in america_uses.items():\n",
        "  print(\"President: \" + president + \". Times using 'America' in address: \" + str(value))"
      ],
      "metadata": {
        "id": "Cl4IEzJzup6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the biggest differences I saw were in the lexical density and"
      ],
      "metadata": {
        "id": "BE_6P8CNLZeo"
      }
    }
  ]
}